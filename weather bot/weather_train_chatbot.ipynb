{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"weather_train_chatbot.ipynb","provenance":[],"mount_file_id":"1uTB89o3r4jd8bCr9EYBnhCEfSfrEosB-","authorship_tag":"ABX9TyNdi+MG3LYbnG4mqGy6pX6v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"8fFa_Ib6E_G1","colab_type":"code","outputId":"9b869482-2ebc-44a7-aea7-2e39e26216eb","executionInfo":{"status":"ok","timestamp":1588602390158,"user_tz":-420,"elapsed":32434,"user":{"displayName":"Chức Nguyễn Văn","photoUrl":"","userId":"13843679832843861597"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k_rzjGVgEoUI","colab_type":"code","colab":{}},"source":["!pip install nltk"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ja3cXNChQ6NR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":326},"outputId":"5ebfbbc3-0309-489f-aef0-1873c747693a","executionInfo":{"status":"ok","timestamp":1592061597831,"user_tz":-420,"elapsed":8147,"user":{"displayName":"Chức Nguyễn Văn","photoUrl":"","userId":"13843679832843861597"}}},"source":["!pip install pyvi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting pyvi\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/e1/0e5bc6b5e3327b9385d6e0f1b0a7c0404f28b74eb6db59a778515b30fd9c/pyvi-0.1-py2.py3-none-any.whl (8.5MB)\n","\u001b[K     |████████████████████████████████| 8.5MB 5.7MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.22.2.post1)\n","Collecting sklearn-crfsuite\n","  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.18.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (0.15.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.4.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.8.7)\n","Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (1.12.0)\n","Collecting python-crfsuite>=0.8.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n","\u001b[K     |████████████████████████████████| 747kB 33.3MB/s \n","\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n","Successfully installed python-crfsuite-0.9.7 pyvi-0.1 sklearn-crfsuite-0.3.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sLeRP704FpSZ","colab_type":"code","outputId":"cad06cd0-eec0-49b2-db88-9b438797f929","executionInfo":{"status":"ok","timestamp":1588602540722,"user_tz":-420,"elapsed":3952,"user":{"displayName":"Chức Nguyễn Văn","photoUrl":"","userId":"13843679832843861597"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["!pip install keras"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6H1NEBi8F0e5","colab_type":"code","colab":{}},"source":["#import and load data\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","lemmatize= WordNetLemmatizer()\n","import json\n","import pickle\n","\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout\n","from keras.optimizers import SGD\n","import random\n","\n","#be ready to load data\n","words       =[] # mảng lưu trũ các từ sau khi được tách ra khỏi câu\n","classes     =[] # mảng lưu trữ các tag\n","documents   =[] # tập hợp các từ tương ứng với tag của chứng cho mỗi intent\n","\n","with open('/content/drive/My Drive/Python code/Chatbot/weather bot/stopwords.txt') as f:\n","    ignore_words=f.read().splitlines()\n","\n","# print(type(ignore_words))\n","# print(ignore_words)\n","#load data\n","data_file   = open('/content/drive/My Drive/Python code/Chatbot/weather bot/weather_intents.json').read()\n","intents     = json.loads(data_file)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ApjEC4KvIrDd","colab_type":"code","colab":{}},"source":["# data_file   = open('/content/drive/My Drive/Python code/Chatbot/intents2.json').read()\n","# print(data_file)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kj8za_JQJJOl","colab":{}},"source":["# data_file   = open('/content/drive/My Drive/Python code/Chatbot/intents.json').read()\n","# print(data_file)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VKiHxMijHRNI","colab_type":"code","outputId":"b7d12ea6-0376-4013-fdeb-211e1c1a3890","executionInfo":{"status":"ok","timestamp":1592065089702,"user_tz":-420,"elapsed":1177,"user":{"displayName":"Chức Nguyễn Văn","photoUrl":"","userId":"13843679832843861597"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["from pyvi import ViTokenizer\n","nltk.download('punkt')\n","#preprocessing data\n","for intent in intents[\"intents\"]:\n","  for pattern in intent[\"patterns\"]:\n","\n","    #tokenize each word\n","    # w= nltk.word_tokenize(pattern)\n","    w= ViTokenizer.tokenize(pattern)\n","    words.extend(w) # Thêm các từ vào tập các từ\n","    #add document to corpus\n","    documents.append((w,intent['tag']))\n","\n","    #add to our classes list\n","    if intent['tag'] not in classes:\n","      classes.append(intent['tag'])\n","\n"],"execution_count":26,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dfUBsDBPI6gC","colab_type":"code","outputId":"38a7e526-fe34-4477-c214-07b9674100af","executionInfo":{"status":"ok","timestamp":1592065106957,"user_tz":-420,"elapsed":1058,"user":{"displayName":"Chức Nguyễn Văn","photoUrl":"","userId":"13843679832843861597"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["nltk.download('wordnet')\n","#lemmatize: chuyển hóa các từ trong tiếng anh về dạng nguyên thể của nó.\n","# words   = [lemmatize.lemmatize(w.lower()) for w in words if w not in ignore_words]\n","words   = [w.lower() for w in words if w not in ignore_words]\n","words   = sorted(list(set(words))) #delete the duplicate in words\n","classes = sorted(list(set(classes)))\n","\n","#document is combination of pattern and intents\n","print(\"there are\", len(documents),\"documents\")\n","print(\"All class\")\n","for i, class_ in enumerate(classes):\n","  print(\"%d : %s\"%(i,class_))\n","print(\"number of unique words: \", len(words))\n","\n","pickle.dump(words,open(\"/content/drive/My Drive/Python code/Chatbot/weather bot/weather_words2.pkl\",\"wb\"))\n","pickle.dump(classes,open(\"/content/drive/My Drive/Python code/Chatbot/weather bot/weather_classes2.pkl\",\"wb\"))"],"execution_count":28,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","there are 192 documents\n","All class\n","0 : goodbye\n","1 : greeting\n","2 : precipitation\n","3 : sunny\n","4 : temperature\n","5 : thanks\n","6 : time\n","7 : uv\n","8 : weather\n","number of unique words:  61\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m6H6SGo1MfoB","colab_type":"code","outputId":"b0c4d831-2611-4377-c3ec-dbe2bc059836","executionInfo":{"status":"ok","timestamp":1592065113252,"user_tz":-420,"elapsed":1052,"user":{"displayName":"Chức Nguyễn Văn","photoUrl":"","userId":"13843679832843861597"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#create training and testing data\n","\n","#create trainning data\n","training=[]\n","#create an empty array for output\n","output_array= [0]*len(classes)\n","# training set, bag of words for each sentence\n","for doc in documents:\n","  #initial bag of words\n","  bag=[]\n","  #list of tokenize word for \n","  pattern_words= doc[0]\n","  #lemmatize each word- create base word,\n","  # in attemp to present related word\n","#   pattern_words=[lemmatize.lemmatize(word.lower()) for word in pattern_words]\n","\n","  for w in words:\n","    bag.append(1) if w in pattern_words else bag.append(0)\n","    output_row=list(output_array)\n","    output_row[classes.index(doc[1])]=1\n","    training.append([bag,output_row])\n","\n","random.shuffle(training)\n","training = np.array(training)\n","# create train and test lists. X - patterns, Y - intents\n","train_x = list(training[:,0])\n","train_y = list(training[:,1])\n","print(\"Training data created\")\n","\n","\n"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Training data created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JeU5mh-ASs4z","colab_type":"code","outputId":"4b6473c7-f646-48f6-c7c8-72c77b11ac8b","executionInfo":{"status":"ok","timestamp":1592064059737,"user_tz":-420,"elapsed":961711,"user":{"displayName":"Chức Nguyễn Văn","photoUrl":"","userId":"13843679832843861597"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#build the model\n","# create model with 3 layers. First layer 128 neurons,\n","#second layer 64 neurons and the output contain the number of neurons\n","#equal the number of classes \n","model= Sequential()\n","model.add(Dense(128,input_shape=(len(train_x[0]),), activation= 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(64,activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(train_y[0]),activation='softmax'))\n","\n","# Compile model. Stochastic gradient descent with Nesterov accelerated \n","# gradient gives good results for this model\n","sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","\n","#fitting and saving the model \n","hist = model.fit(np.array(train_x), np.array(train_y), epochs=50, batch_size=5, verbose=1)\n","# model.save('/content/drive/My Drive/Python code/Chatbot/weather bot/weather_chatbot_model.h5', hist) # cos pyvi va stopwords\n","model.save('/content/drive/My Drive/Python code/Chatbot/weather bot/weather_chatbot_model2.h5', hist) # ko pyvi va stopword\n","print(\"model created\")"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","27840/27840 [==============================] - 19s 699us/step - loss: 0.1854 - accuracy: 0.9329\n","Epoch 2/50\n","27840/27840 [==============================] - 19s 690us/step - loss: 0.0691 - accuracy: 0.9677\n","Epoch 3/50\n","27840/27840 [==============================] - 19s 674us/step - loss: 0.0630 - accuracy: 0.9686\n","Epoch 4/50\n","27840/27840 [==============================] - 20s 702us/step - loss: 0.0613 - accuracy: 0.9686\n","Epoch 5/50\n","27840/27840 [==============================] - 19s 675us/step - loss: 0.0598 - accuracy: 0.9687\n","Epoch 6/50\n","27840/27840 [==============================] - 20s 702us/step - loss: 0.0600 - accuracy: 0.9677\n","Epoch 7/50\n","27840/27840 [==============================] - 19s 678us/step - loss: 0.0609 - accuracy: 0.9672\n","Epoch 8/50\n","27840/27840 [==============================] - 19s 679us/step - loss: 0.0587 - accuracy: 0.9679\n","Epoch 9/50\n","27840/27840 [==============================] - 19s 693us/step - loss: 0.0586 - accuracy: 0.9676\n","Epoch 10/50\n","27840/27840 [==============================] - 19s 675us/step - loss: 0.0580 - accuracy: 0.9678\n","Epoch 11/50\n","27840/27840 [==============================] - 19s 696us/step - loss: 0.0584 - accuracy: 0.9683\n","Epoch 12/50\n","27840/27840 [==============================] - 20s 702us/step - loss: 0.0581 - accuracy: 0.9669\n","Epoch 13/50\n","27840/27840 [==============================] - 19s 693us/step - loss: 0.0573 - accuracy: 0.9685\n","Epoch 14/50\n","27840/27840 [==============================] - 18s 660us/step - loss: 0.0574 - accuracy: 0.9684\n","Epoch 15/50\n","27840/27840 [==============================] - 19s 690us/step - loss: 0.0568 - accuracy: 0.9685\n","Epoch 16/50\n","27840/27840 [==============================] - 19s 700us/step - loss: 0.0575 - accuracy: 0.9675\n","Epoch 17/50\n","27840/27840 [==============================] - 19s 676us/step - loss: 0.0566 - accuracy: 0.9688\n","Epoch 18/50\n","27840/27840 [==============================] - 20s 704us/step - loss: 0.0568 - accuracy: 0.9679\n","Epoch 19/50\n","27840/27840 [==============================] - 19s 683us/step - loss: 0.0571 - accuracy: 0.9688\n","Epoch 20/50\n","27840/27840 [==============================] - 20s 709us/step - loss: 0.0571 - accuracy: 0.9682\n","Epoch 21/50\n","27840/27840 [==============================] - 19s 693us/step - loss: 0.0567 - accuracy: 0.9692\n","Epoch 22/50\n","27840/27840 [==============================] - 20s 704us/step - loss: 0.0567 - accuracy: 0.9676\n","Epoch 23/50\n","27840/27840 [==============================] - 19s 695us/step - loss: 0.0569 - accuracy: 0.9680\n","Epoch 24/50\n","27840/27840 [==============================] - 18s 661us/step - loss: 0.0562 - accuracy: 0.9677\n","Epoch 25/50\n","27840/27840 [==============================] - 20s 704us/step - loss: 0.0565 - accuracy: 0.9693\n","Epoch 26/50\n","27840/27840 [==============================] - 19s 689us/step - loss: 0.0572 - accuracy: 0.9681\n","Epoch 27/50\n","27840/27840 [==============================] - 19s 694us/step - loss: 0.0566 - accuracy: 0.9679\n","Epoch 28/50\n","27840/27840 [==============================] - 19s 698us/step - loss: 0.0566 - accuracy: 0.9679\n","Epoch 29/50\n","27840/27840 [==============================] - 18s 661us/step - loss: 0.0563 - accuracy: 0.9686\n","Epoch 30/50\n","27840/27840 [==============================] - 19s 691us/step - loss: 0.0564 - accuracy: 0.9690\n","Epoch 31/50\n","27840/27840 [==============================] - 19s 697us/step - loss: 0.0568 - accuracy: 0.9683\n","Epoch 32/50\n","27840/27840 [==============================] - 19s 686us/step - loss: 0.0568 - accuracy: 0.9672\n","Epoch 33/50\n","27840/27840 [==============================] - 19s 690us/step - loss: 0.0563 - accuracy: 0.9673\n","Epoch 34/50\n","27840/27840 [==============================] - 19s 684us/step - loss: 0.0570 - accuracy: 0.9676\n","Epoch 35/50\n","27840/27840 [==============================] - 19s 672us/step - loss: 0.0565 - accuracy: 0.9674\n","Epoch 36/50\n","27840/27840 [==============================] - 20s 723us/step - loss: 0.0562 - accuracy: 0.9687\n","Epoch 37/50\n","27840/27840 [==============================] - 19s 668us/step - loss: 0.0561 - accuracy: 0.9681\n","Epoch 38/50\n","27840/27840 [==============================] - 20s 702us/step - loss: 0.0572 - accuracy: 0.9677\n","Epoch 39/50\n","27840/27840 [==============================] - 20s 710us/step - loss: 0.0564 - accuracy: 0.9684\n","Epoch 40/50\n","27840/27840 [==============================] - 19s 682us/step - loss: 0.0568 - accuracy: 0.9686\n","Epoch 41/50\n","27840/27840 [==============================] - 19s 698us/step - loss: 0.0561 - accuracy: 0.9690\n","Epoch 42/50\n","27840/27840 [==============================] - 19s 690us/step - loss: 0.0560 - accuracy: 0.9689\n","Epoch 43/50\n","27840/27840 [==============================] - 20s 710us/step - loss: 0.0558 - accuracy: 0.9682\n","Epoch 44/50\n","27840/27840 [==============================] - 19s 677us/step - loss: 0.0562 - accuracy: 0.9694\n","Epoch 45/50\n","27840/27840 [==============================] - 19s 697us/step - loss: 0.0559 - accuracy: 0.9679\n","Epoch 46/50\n","27840/27840 [==============================] - 19s 697us/step - loss: 0.0558 - accuracy: 0.9686\n","Epoch 47/50\n","27840/27840 [==============================] - 19s 693us/step - loss: 0.0561 - accuracy: 0.9684\n","Epoch 48/50\n","27840/27840 [==============================] - 19s 672us/step - loss: 0.0567 - accuracy: 0.9676\n","Epoch 49/50\n","27840/27840 [==============================] - 19s 688us/step - loss: 0.0561 - accuracy: 0.9686\n","Epoch 50/50\n","27840/27840 [==============================] - 19s 677us/step - loss: 0.0559 - accuracy: 0.9690\n","model created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w8oItjwlWEDA","colab_type":"code","outputId":"510f0efe-3a58-4566-c410-1e86ea59af79","executionInfo":{"status":"ok","timestamp":1588606916469,"user_tz":-420,"elapsed":828,"user":{"displayName":"Chức Nguyễn Văn","photoUrl":"","userId":"13843679832843861597"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["print(len(train_x))\n","print(len(train_y))\n","# print(train_x[:20])\n","print(len(train_x[0]))\n","print(train_y[:5])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1482\n","1482\n","57\n","[[0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KRb21NwxE5oC","colab_type":"code","outputId":"3413fe49-f00b-4019-c524-15b798ea634d","executionInfo":{"status":"ok","timestamp":1592041685803,"user_tz":-420,"elapsed":7747,"user":{"displayName":"Chức Nguyễn Văn","photoUrl":"","userId":"13843679832843861597"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["!pip install fuzzywuzzy"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting fuzzywuzzy\n","  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n","Installing collected packages: fuzzywuzzy\n","Successfully installed fuzzywuzzy-0.18.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eKIsExPbE17c","colab_type":"code","outputId":"a4c31bf4-9306-4fbe-c8f4-1cdddc24ef58","executionInfo":{"status":"ok","timestamp":1592041706932,"user_tz":-420,"elapsed":2329,"user":{"displayName":"Chức Nguyễn Văn","photoUrl":"","userId":"13843679832843861597"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["from fuzzywuzzy import fuzz\n","Str1 = \"Apple Inc.\"\n","Str2 = \"apple Inc\"\n","Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n","print(Ratio)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["95\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n","  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qFrnMU95F1YR","colab_type":"code","colab":{}},"source":["with open(\"/content/drive/My Drive/Python code/Chatbot/data.txt\") as f:\n","    city=f.read().splitlines()\n","    city= [ci.lower() for ci in city]\n","\n","# print(city)\n","\n","\n","a=\"ngày mai thời tiết La gi như thế nào\"\n","\n","rate= [fuzz.ratio(a)]\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q1k7Q9bxauhB","colab_type":"text"},"source":["#Mạng CNN"]},{"cell_type":"code","metadata":{"id":"VI-ReQFFasIn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"fdc7b339-c02e-48d4-9b5a-8c763358ce14","executionInfo":{"status":"ok","timestamp":1592065627959,"user_tz":-420,"elapsed":395145,"user":{"displayName":"Chức Nguyễn Văn","photoUrl":"","userId":"13843679832843861597"}}},"source":["\n","from keras import layers\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","from keras.preprocessing.text import Tokenizer, one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","from keras.utils import np_utils\n","from pyvi import ViTokenizer, ViPosTagger\n","\n","\n","# Define CNN architecture\n","embedding_dim = 128\n","model2    = Sequential()\n","model2.add(layers.Embedding(len(train_x), embedding_dim, input_length=len(train_x[0])))\n","model2.add(layers.Conv1D(128, 5, activation='relu'))\n","model2.add(layers.GlobalMaxPooling1D())\n","model2.add(layers.Dense(128, activation='relu'))\n","model2.add(layers.Dropout(0.5))\n","model2.add(layers.Dense(len(train_y[0]), activation='softmax'))\n","model2.compile( optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n","        \n","#fitting and saving the model \n","hist = model2.fit(np.array(train_x), np.array(train_y), epochs=30, batch_size=5, verbose=1)\n","# model.save('/content/drive/My Drive/Python code/Chatbot/weather bot/weather_chatbot_model.h5', hist) # cos pyvi va stopwords\n","model2.save('/content/drive/My Drive/Python code/Chatbot/weather bot/weather_chatbot_model3.h5', hist) # ko pyvi va stopword\n","print(\"model created\")"],"execution_count":31,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 1.1657 - accuracy: 0.5346\n","Epoch 2/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.4696 - accuracy: 0.7941\n","Epoch 3/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.3546 - accuracy: 0.8410\n","Epoch 4/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.3123 - accuracy: 0.8538\n","Epoch 5/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2867 - accuracy: 0.8648\n","Epoch 6/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2669 - accuracy: 0.8727\n","Epoch 7/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2639 - accuracy: 0.8741\n","Epoch 8/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2514 - accuracy: 0.8756\n","Epoch 9/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2468 - accuracy: 0.8816\n","Epoch 10/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2448 - accuracy: 0.8791\n","Epoch 11/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2368 - accuracy: 0.8793\n","Epoch 12/30\n","11712/11712 [==============================] - 14s 1ms/step - loss: 0.2362 - accuracy: 0.8838\n","Epoch 13/30\n","11712/11712 [==============================] - 14s 1ms/step - loss: 0.2335 - accuracy: 0.8814\n","Epoch 14/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2314 - accuracy: 0.8844\n","Epoch 15/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2287 - accuracy: 0.8843\n","Epoch 16/30\n","11712/11712 [==============================] - 14s 1ms/step - loss: 0.2236 - accuracy: 0.8858\n","Epoch 17/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2237 - accuracy: 0.8868\n","Epoch 18/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2233 - accuracy: 0.8852\n","Epoch 19/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2224 - accuracy: 0.8871\n","Epoch 20/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2263 - accuracy: 0.8831\n","Epoch 21/30\n","11712/11712 [==============================] - 14s 1ms/step - loss: 0.2197 - accuracy: 0.8887\n","Epoch 22/30\n","11712/11712 [==============================] - 14s 1ms/step - loss: 0.2155 - accuracy: 0.8868\n","Epoch 23/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2255 - accuracy: 0.8838\n","Epoch 24/30\n","11712/11712 [==============================] - 14s 1ms/step - loss: 0.2201 - accuracy: 0.8876\n","Epoch 25/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2183 - accuracy: 0.8883\n","Epoch 26/30\n","11712/11712 [==============================] - 14s 1ms/step - loss: 0.2174 - accuracy: 0.8905\n","Epoch 27/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2182 - accuracy: 0.8858\n","Epoch 28/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2165 - accuracy: 0.8896\n","Epoch 29/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2109 - accuracy: 0.8906\n","Epoch 30/30\n","11712/11712 [==============================] - 13s 1ms/step - loss: 0.2138 - accuracy: 0.8922\n","model created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NtWN5jI9h6k5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"80f13f4a-e84a-40d9-d039-50e7e8532de9","executionInfo":{"status":"ok","timestamp":1592067865433,"user_tz":-420,"elapsed":1221,"user":{"displayName":"Chức Nguyễn Văn","photoUrl":"","userId":"13843679832843861597"}}},"source":["import nltk\n","from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","import pickle\n","import numpy as np\n","from keras.models import load_model\n","model_real = load_model('/content/drive/My Drive/Python code/Chatbot/weather bot/model_no_pyvi/weather_chatbot_model2.h5')\n","import json\n","# import random\n","# print(open('intents.json').read()[440:446])\n","# intents = json.loads(open('intents.json').read())\n","intents= json.loads(open('/content/drive/My Drive/Python code/Chatbot/weather bot/weather_intents.json',\"rb\").read().decode(\"utf-8\", \"ignore\"))\n","words = pickle.load(open('/content/drive/My Drive/Python code/Chatbot/weather bot/model_no_pyvi/weather_words2.pkl','rb'))\n","classes = pickle.load(open('/content/drive/My Drive/Python code/Chatbot/weather bot/model_no_pyvi/weather_classes2.pkl','rb'))\n","\n","with open('/content/drive/My Drive/Python code/Chatbot/weather bot/stopwords.txt') as f:\n","    stopwords_1= f.read().splitlines()\n","\n","def clean_up_sentence(sentence):\n","    \n","    # tokenize the pattern - split words into array\n","    sentence_words = nltk.word_tokenize(sentence)\n","    # sentence_words = ViTokenizer.tokenize(sentence)\n","    # stem each word - create short form for word\n","    # sentence_words = [word.lower() for word in sentence_words if word not in stopwords_1 ]\n","    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words ]\n","    return sentence_words\n","# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n","def bow(sentence, words, show_details=True):\n","    # tokenize the pattern\n","    sentence_words = clean_up_sentence(sentence)\n","    # bag of words - matrix of N words, vocabulary matrix\n","    bag = [0]*len(words)\n","    for s in sentence_words:\n","        for i,w in enumerate(words):\n","            if w == s:\n","                # assign 1 if current word is in the vocabulary position\n","                bag[i] = 1\n","                if show_details:\n","                    print (\"found in bag: %s\" % w)\n","    return(np.array(bag))\n","\n","def predict_class(sentence, model):\n","    # filter out predictions below a threshold\n","    p = bow(sentence, words,show_details=False)\n","    res = model.predict(np.array([p]))[0]\n","    ERROR_THRESHOLD = 0.25\n","    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n","    # sort by strength of probability\n","    results.sort(key=lambda x: x[1], reverse=True)\n","    return_list = []\n","    for r in results:\n","        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n","    return return_list\n","\n","# def getResponse(ints, intents_json):\n","#     tag = ints[0]['intent']\n","#     list_of_intents = intents_json['intents']\n","#     for i in list_of_intents:\n","#         if(i['tag']== tag):\n","#             result = random.choice(i['responses'])\n","#             break\n","#     return result\n","\n","\n","# def chatbot_response(text):\n","#     ints = predict_class(text, model)\n","#     res = getResponse(ints, intents)\n","#     return res\n","\n","a=\"mai rán trứng không cần mỡ được không\"\n","result=predict_class(a,model_real)\n","for re in result:\n","    print(re[\"intent\"] ,\" : \", re[\"probability\"])\n"],"execution_count":56,"outputs":[{"output_type":"stream","text":["precipitation  :  1.0\n"],"name":"stdout"}]}]}